FROM ubuntu

MAINTAINER KiwenLau <kiwenlau@gmail.com>

WORKDIR /root
RUN  apt-get  update && apt-get install net-tools  python openssh-server vim expect wget inetutils-ping  curl -y  &&\
     apt-get  clean
COPY startnode.sh /root/
ADD  jdk-8u65-linux-x64.tar.gz /usr/local/
RUN  mv /usr/local/jdk1.8.0_65 /usr/local/jdk1.8 &&\
     rm -rf jdk-8u65-linux-x64.tar.gz
# install hadoop 2.7.2
ADD  hadoop-2.7.5.tar.gz /usr/local
RUN  mv /usr/local/hadoop-2.7.5 /usr/local/hadoop && \
     rm  -rf hadoop-2.7.5.tar.gz
# set environment variable
ENV JAVA_HOME=/usr/local/jdk1.8
ENV HADOOP_HOME=/usr/local/hadoop
ENV PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin 

#install scala 
ADD  scala-2.10.4.tgz  /usr/local/
RUN  mv /usr/local/scala-2.10.4  /usr/local/scala &&\
     rm -rf scala-2.10.4.tgz
# install spark-2.3.0-bin-hadoop2.7
ADD  spark-2.3.0-bin-hadoop2.7.tgz  /usr/local/
RUN  mv /usr/local/spark-2.3.0-bin-hadoop2.7  /usr/local/spark &&\
     rm -rf spark-2.3.0-bin-hadoop2.7.tgz
ENV  SCALA_HOME=/usr/local/scala
ENV  SPARK_HOME=/usr/local/spark
ENV  PATH=$PATH:$SCALA_HOME/bin

#install hbase
ADD hbase-1.2.6-bin.tar.gz /usr/local/
RUN  mv /usr/local/hbase-1.2.6  /usr/local/hbase &&\
     rm -rf hbase-1.2.6-bin.tar.gz
ENV  HBASE_HOME=/usr/local/hbase
ENV  PATH=$PATH:$HBASE_HOME/bin
ENV  HBASE_CLASSPATH=$HBASE_HOME/conf
ENV  HBASE_LOG_DIR=$HBASE_HOME/logs

#install hive
ADD  apache-hive-1.2.2-bin.tar.gz  /usr/local/
RUN  mv /usr/local/apache-hive-1.2.2-bin  /usr/local/hive &&\
     rm -rf apache-hive-1.2.2-bin.tar.gz
ENV  HIVE_HOME=/usr/local/hive
ENV  PATH=$PATH:$HIVE_HOME/bin
COPY mysql-connector-java-5.1.41-bin.jar /usr/local/hive/lib/

#install storm

ADD   apache-storm-1.2.1.tar.gz /usr/local/
RUN   mv /usr/local/apache-storm-1.2.1  /usr/local/storm &&\
      rm -rf apache-storm-1.2.1.tar.gz
ENV   STORM_HOME=/usr/local/storm
ENV   PATH=$PATH:$STROM_HOME/bin
# ssh without key
RUN ssh-keygen -t rsa -f ~/.ssh/id_rsa -P '' && \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys

RUN mkdir -p ~/hdfs/namenode && \ 
    mkdir -p ~/hdfs/datanode && \
    mkdir $HADOOP_HOME/logs  && \
    mkdir $HBASE_HOME/logs

COPY config/* /tmp/

RUN mv /tmp/ssh_config ~/.ssh/config && \
    mv /tmp/hadoop-env.sh /usr/local/hadoop/etc/hadoop/hadoop-env.sh && \
    mv /tmp/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml && \ 
    mv /tmp/storm.yaml   $STORM_HOME/conf/storm.yaml && \ 
    mv /tmp/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml && \
    mv /tmp/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml && \
    mv /tmp/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml && \
    cp /tmp/slaves $HADOOP_HOME/etc/hadoop/slaves && \
    cp /tmp/slaves  $SPARK_HOME/conf/slaves && \
    cp /tmp/regionservers  $HBASE_HOME/conf/regionservers && \
    cp /tmp/hbase-env.sh  $HBASE_HOME/conf/hbase-env.sh && \
    cp /tmp/hbase-site.xml $HBASE_HOME/conf/hbase-site.xml && \ 
    cp /tmp/hive-site.xml $HIVE_HOME/conf/hive-site.xml && \ 
    mv /tmp/spark-env.sh  $SPARK_HOME/conf/spark-env.sh && \
    mv /tmp/start-hadoop.sh ~/start-hadoop.sh && \
    mv /tmp/start-slaves-storm.sh  ~/start-slaves-storm.sh && \
    mv /tmp/start-master-storm.sh  ~/start-master-storm.sh && \
    mv /tmp/stop-master-storm.sh  ~/stop-master-storm.sh && \
    mv /tmp/stop-slaves-storm.sh  ~/stop-slaves-storm.sh && \
    mv /tmp/expect.sh ~/expect.sh && \
    mv /tmp/auto-install-mysql.sh  ~/auto-install-mysql.sh && \
    mv /tmp/run-wordcount.sh ~/run-wordcount.sh

RUN chmod +x ~/start-hadoop.sh && \
    chmod +x ~/run-wordcount.sh && \
    chmod +x $HADOOP_HOME/sbin/start-dfs.sh && \
    chmod +x $HADOOP_HOME/sbin/start-yarn.sh && \
    chmod +x  expect.sh  && \
    chmod +x  auto-install-mysql.sh  &&\ 
    chmod +x /root/startnode.sh
# format namenode
RUN hdfs namenode -format

CMD [ "sh", "-c", "service ssh start; bash"]